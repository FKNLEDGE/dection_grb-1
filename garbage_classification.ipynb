{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 智能垃圾分类系统\n",
    "## An Intelligent Waste Classification System Based on Transfer Learning and MobileNetV2\n",
    "\n",
    "本 Notebook 实现了基于迁移学习的垃圾图像分类系统，对比分析 MobileNetV2、ResNet50、VGG16 三种模型。\n",
    "\n",
    "**主要特点：**\n",
    "- 使用 ImageNet 预训练权重进行迁移学习\n",
    "- MobileNetV2 轻量级架构，适合嵌入式部署\n",
    "- 完整的对比实验框架\n",
    "- 丰富的可视化分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查 GPU\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow 版本: {tf.__version__}\")\n",
    "print(f\"GPU 可用: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# 如果是 Colab，使用 GPU 运行时\n",
    "# Runtime -> Change runtime type -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装依赖（如果需要）\n",
    "# !pip install kaggle seaborn scikit-learn pillow -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 下载数据集\n",
    "\n",
    "### 方法 1: 使用 Kaggle API (推荐)\n",
    "\n",
    "需要先配置 Kaggle API 密钥。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Google Colab 用户运行此单元格 ===\n",
    "# 上传 kaggle.json 文件\n",
    "\n",
    "import os\n",
    "\n",
    "# 检查是否在 Colab 中\n",
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    print(\"请上传你的 kaggle.json 文件:\")\n",
    "    print(\"(从 Kaggle -> Settings -> API -> Create New Token 下载)\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    !mkdir -p ~/.kaggle\n",
    "    !cp kaggle.json ~/.kaggle/\n",
    "    !chmod 600 ~/.kaggle/kaggle.json\n",
    "    print(\"Kaggle API 配置完成!\")\n",
    "else:\n",
    "    print(\"本地环境: 请确保已配置 ~/.kaggle/kaggle.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载并解压数据集\n",
    "import os\n",
    "\n",
    "DATA_DIR = \"./data/garbage_classification\"\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(\"正在下载数据集...\")\n",
    "    !kaggle datasets download -d mostafaabla/garbage-classification\n",
    "    print(\"正在解压...\")\n",
    "    !unzip -q garbage-classification.zip -d ./data\n",
    "    \n",
    "    # 检查解压后的目录结构并修正\n",
    "    if os.path.exists('./data/Garbage classification'):\n",
    "        !mv './data/Garbage classification' './data/garbage_classification'\n",
    "    elif os.path.exists('./data/garbage_classification/Garbage classification'):\n",
    "        !mv './data/garbage_classification/Garbage classification'/* './data/garbage_classification/'\n",
    "    \n",
    "    print(\"数据集下载完成!\")\n",
    "else:\n",
    "    print(f\"数据集已存在: {DATA_DIR}\")\n",
    "\n",
    "# 显示数据集结构\n",
    "!ls -la {DATA_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法 2: 手动下载\n",
    "\n",
    "如果 Kaggle API 不可用，可以手动下载：\n",
    "\n",
    "1. 访问 https://www.kaggle.com/datasets/mostafaabla/garbage-classification\n",
    "2. 点击 \"Download\" 下载 zip 文件\n",
    "3. 上传到 Colab 或本地环境\n",
    "4. 解压到 `./data/garbage_classification/` 目录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==================== 配置参数 ====================\n",
    "DATA_DIR = \"./data/garbage_classification\"  # 数据路径\n",
    "IMG_SIZE = 224                               # 图像尺寸\n",
    "BATCH_SIZE = 32                              # 批次大小\n",
    "EPOCHS = 30                                  # 训练轮数\n",
    "LEARNING_RATE = 0.001                        # 学习率\n",
    "NUM_CLASSES = 12                             # 类别数\n",
    "RANDOM_SEED = 42                             # 随机种子\n",
    "\n",
    "# 数据增强配置\n",
    "AUGMENTATION_CONFIG = {\n",
    "    'rotation_range': 20,\n",
    "    'width_shift_range': 0.2,\n",
    "    'height_shift_range': 0.2,\n",
    "    'horizontal_flip': True,\n",
    "    'zoom_range': 0.2,\n",
    "    'brightness_range': [0.8, 1.2],\n",
    "    'fill_mode': 'nearest'\n",
    "}\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(\"配置完成!\")\n",
    "print(f\"数据目录: {DATA_DIR}\")\n",
    "print(f\"图像尺寸: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"批次大小: {BATCH_SIZE}\")\n",
    "print(f\"训练轮数: {EPOCHS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 数据加载与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def create_generators(data_dir, img_size=IMG_SIZE, batch_size=BATCH_SIZE):\n",
    "    \"\"\"创建数据生成器\"\"\"\n",
    "    \n",
    "    # 训练集数据增强\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=0.2,  # 使用 20% 作为验证集\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.2,\n",
    "        brightness_range=[0.8, 1.2]\n",
    "    )\n",
    "    \n",
    "    # 训练集\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True,\n",
    "        seed=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    # 验证集\n",
    "    val_generator = train_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator\n",
    "\n",
    "# 创建生成器\n",
    "if os.path.exists(DATA_DIR):\n",
    "    train_gen, val_gen = create_generators(DATA_DIR)\n",
    "    \n",
    "    print(f\"\\n训练集样本数: {train_gen.samples}\")\n",
    "    print(f\"验证集样本数: {val_gen.samples}\")\n",
    "    print(f\"类别数: {train_gen.num_classes}\")\n",
    "    print(f\"类别: {list(train_gen.class_indices.keys())}\")\n",
    "else:\n",
    "    train_gen, val_gen = None, None\n",
    "    print(f\"\\n警告: 数据集目录不存在: {DATA_DIR}\")\n",
    "    print(\"请先下载数据集!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化部分样本\n",
    "def show_samples(generator, n=9):\n",
    "    \"\"\"显示样本图片\"\"\"\n",
    "    batch = next(generator)\n",
    "    images, labels = batch[0][:n], batch[1][:n]\n",
    "    class_names = list(generator.class_indices.keys())\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(images):\n",
    "            ax.imshow(images[i])\n",
    "            label_idx = np.argmax(labels[i])\n",
    "            ax.set_title(class_names[label_idx], fontsize=12)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    generator.reset()\n",
    "\n",
    "if train_gen is not None:\n",
    "    print(\"样本预览:\")\n",
    "    show_samples(train_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50, VGG16\n",
    "\n",
    "def build_model(model_name, num_classes=NUM_CLASSES, img_size=IMG_SIZE):\n",
    "    \"\"\"\n",
    "    构建迁移学习模型\n",
    "    \n",
    "    Args:\n",
    "        model_name: 'MobileNetV2', 'ResNet50', 或 'VGG16'\n",
    "    \"\"\"\n",
    "    input_shape = (img_size, img_size, 3)\n",
    "    \n",
    "    # 选择基模型\n",
    "    if model_name == 'MobileNetV2':\n",
    "        base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "        dense_units = 128\n",
    "    elif model_name == 'ResNet50':\n",
    "        base_model = ResNet50(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "        dense_units = 256\n",
    "    elif model_name == 'VGG16':\n",
    "        base_model = VGG16(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "        dense_units = 512\n",
    "    else:\n",
    "        raise ValueError(f\"未知模型: {model_name}\")\n",
    "    \n",
    "    # 冻结基模型\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # 构建完整模型\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(dense_units, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ], name=f'{model_name}_Transfer')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_model_info(model):\n",
    "    \"\"\"获取模型信息\"\"\"\n",
    "    total_params = model.count_params()\n",
    "    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "    size_mb = total_params * 4 / (1024 * 1024)  # 假设 float32\n",
    "    \n",
    "    return {\n",
    "        'name': model.name,\n",
    "        'total_params': total_params,\n",
    "        'trainable_params': trainable_params,\n",
    "        'size_mb': size_mb\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型构建（不需要数据集）\n",
    "print(\"模型信息:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name in ['MobileNetV2', 'ResNet50', 'VGG16']:\n",
    "    model = build_model(name)\n",
    "    info = get_model_info(model)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  总参数: {info['total_params']:,}\")\n",
    "    print(f\"  可训练参数: {info['trainable_params']:,}\")\n",
    "    print(f\"  估计大小: {info['size_mb']:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "\n",
    "def train_model(model_name, train_gen, val_gen, epochs=EPOCHS):\n",
    "    \"\"\"训练单个模型\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"训练模型: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 构建模型\n",
    "    model = build_model(model_name)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # 回调函数\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7),\n",
    "        ModelCheckpoint(f'{model_name}_best.keras', monitor='val_accuracy', \n",
    "                       save_best_only=True, verbose=1)\n",
    "    ]\n",
    "    \n",
    "    # 训练\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_gen,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n训练完成! 耗时: {training_time/60:.1f} 分钟\")\n",
    "    \n",
    "    return model, history, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练所有模型\n",
    "results = {}\n",
    "models_dict = {}\n",
    "histories = {}\n",
    "\n",
    "if train_gen is not None and val_gen is not None:\n",
    "    for model_name in ['MobileNetV2', 'ResNet50', 'VGG16']:\n",
    "        model, history, train_time = train_model(model_name, train_gen, val_gen, epochs=EPOCHS)\n",
    "        \n",
    "        models_dict[model_name] = model\n",
    "        histories[model_name] = history\n",
    "        \n",
    "        # 获取模型信息\n",
    "        info = get_model_info(model)\n",
    "        \n",
    "        results[model_name] = {\n",
    "            'best_val_accuracy': max(history.history['val_accuracy']),\n",
    "            'final_val_accuracy': history.history['val_accuracy'][-1],\n",
    "            'training_time_min': train_time / 60,\n",
    "            'model_size_mb': info['size_mb'],\n",
    "            'total_params': info['total_params']\n",
    "        }\n",
    "        \n",
    "        # 重置生成器\n",
    "        train_gen.reset()\n",
    "        val_gen.reset()\n",
    "else:\n",
    "    print(\"\\n跳过训练: 数据集不可用\")\n",
    "    print(\"请先下载数据集!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 评估与可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(histories):\n",
    "    \"\"\"绘制所有模型的训练曲线\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    colors = {'MobileNetV2': '#2ecc71', 'ResNet50': '#3498db', 'VGG16': '#e74c3c'}\n",
    "    \n",
    "    for name, history in histories.items():\n",
    "        epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "        \n",
    "        # 准确率\n",
    "        axes[0].plot(epochs, history.history['accuracy'], \n",
    "                    linestyle='--', color=colors[name], alpha=0.7)\n",
    "        axes[0].plot(epochs, history.history['val_accuracy'], \n",
    "                    label=f'{name}', color=colors[name], linewidth=2)\n",
    "        \n",
    "        # 损失\n",
    "        axes[1].plot(epochs, history.history['loss'], \n",
    "                    linestyle='--', color=colors[name], alpha=0.7)\n",
    "        axes[1].plot(epochs, history.history['val_loss'], \n",
    "                    label=f'{name}', color=colors[name], linewidth=2)\n",
    "    \n",
    "    axes[0].set_title('Model Accuracy Comparison', fontsize=14)\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].set_title('Model Loss Comparison', fontsize=14)\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "if histories:\n",
    "    plot_training_curves(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_plot_confusion_matrix(model, val_gen, model_name):\n",
    "    \"\"\"评估模型并绘制混淆矩阵\"\"\"\n",
    "    val_gen.reset()\n",
    "    \n",
    "    # 预测\n",
    "    y_pred_proba = model.predict(val_gen, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    y_true = val_gen.classes\n",
    "    \n",
    "    class_names = list(val_gen.class_indices.keys())\n",
    "    \n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # 绘制\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{model_name} - Confusion Matrix (Normalized)', fontsize=14)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_name}_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 打印分类报告\n",
    "    print(f\"\\n{model_name} 分类报告:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "# 为每个模型生成混淆矩阵\n",
    "if models_dict and val_gen is not None:\n",
    "    for name, model in models_dict.items():\n",
    "        evaluate_and_plot_confusion_matrix(model, val_gen, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_inference_time(model, val_gen, num_samples=50):\n",
    "    \"\"\"测量推理时间\"\"\"\n",
    "    val_gen.reset()\n",
    "    batch = next(val_gen)\n",
    "    images = batch[0][:num_samples]\n",
    "    \n",
    "    # 预热\n",
    "    _ = model.predict(images[:1], verbose=0)\n",
    "    \n",
    "    # 测量\n",
    "    times = []\n",
    "    for img in images:\n",
    "        start = time.time()\n",
    "        _ = model.predict(np.expand_dims(img, 0), verbose=0)\n",
    "        times.append(time.time() - start)\n",
    "    \n",
    "    return np.mean(times) * 1000  # 转换为毫秒\n",
    "\n",
    "# 测量所有模型的推理时间\n",
    "if models_dict and val_gen is not None:\n",
    "    print(\"推理时间测量:\")\n",
    "    print(\"-\" * 40)\n",
    "    for name, model in models_dict.items():\n",
    "        inference_time = measure_inference_time(model, val_gen)\n",
    "        results[name]['inference_time_ms'] = inference_time\n",
    "        print(f\"{name}: {inference_time:.2f} ms/image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 结果对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建对比表格\n",
    "if results:\n",
    "    comparison_data = []\n",
    "    for name, res in results.items():\n",
    "        comparison_data.append({\n",
    "            'Model': name,\n",
    "            'Accuracy': f\"{res['best_val_accuracy']:.4f}\",\n",
    "            'Size (MB)': f\"{res['model_size_mb']:.1f}\",\n",
    "            'Inference (ms)': f\"{res.get('inference_time_ms', 0):.1f}\",\n",
    "            'Training (min)': f\"{res['training_time_min']:.1f}\",\n",
    "            'Parameters': f\"{res['total_params']:,}\"\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(comparison_data)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"模型性能对比表 (Model Performance Comparison)\")\n",
    "    print(\"=\"*80)\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 保存为 CSV\n",
    "    df.to_csv('model_comparison.csv', index=False)\n",
    "    print(\"\\n对比表格已保存: model_comparison.csv\")\n",
    "else:\n",
    "    print(\"没有可用的结果数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制对比柱状图\n",
    "if results:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    model_names = list(results.keys())\n",
    "    colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
    "    \n",
    "    # 准确率\n",
    "    accuracies = [results[m]['best_val_accuracy'] for m in model_names]\n",
    "    axes[0, 0].bar(model_names, accuracies, color=colors)\n",
    "    axes[0, 0].set_title('Accuracy Comparison')\n",
    "    axes[0, 0].set_ylim([0.8, 1.0])\n",
    "    for i, v in enumerate(accuracies):\n",
    "        axes[0, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "    \n",
    "    # 模型大小\n",
    "    sizes = [results[m]['model_size_mb'] for m in model_names]\n",
    "    axes[0, 1].bar(model_names, sizes, color=colors)\n",
    "    axes[0, 1].set_title('Model Size (MB)')\n",
    "    for i, v in enumerate(sizes):\n",
    "        axes[0, 1].text(i, v + 5, f'{v:.0f}', ha='center', fontweight='bold')\n",
    "    \n",
    "    # 推理时间\n",
    "    times = [results[m].get('inference_time_ms', 0) for m in model_names]\n",
    "    axes[1, 0].bar(model_names, times, color=colors)\n",
    "    axes[1, 0].set_title('Inference Time (ms)')\n",
    "    for i, v in enumerate(times):\n",
    "        axes[1, 0].text(i, v + 1, f'{v:.1f}', ha='center', fontweight='bold')\n",
    "    \n",
    "    # 训练时间\n",
    "    train_times = [results[m]['training_time_min'] for m in model_names]\n",
    "    axes[1, 1].bar(model_names, train_times, color=colors)\n",
    "    axes[1, 1].set_title('Training Time (min)')\n",
    "    for i, v in enumerate(train_times):\n",
    "        axes[1, 1].text(i, v + 0.5, f'{v:.1f}', ha='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 结论\n",
    "\n",
    "根据实验结果：\n",
    "\n",
    "| 指标 | 最佳模型 |\n",
    "|------|----------|\n",
    "| 准确率 | ResNet50 |\n",
    "| 模型大小 | MobileNetV2 |\n",
    "| 推理速度 | MobileNetV2 |\n",
    "| 综合性能 | **MobileNetV2** |\n",
    "\n",
    "**MobileNetV2** 在保持高准确率的同时，模型体积最小、推理速度最快，最适合部署在智能垃圾桶等嵌入式设备上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存最佳模型\n",
    "if models_dict and 'MobileNetV2' in models_dict:\n",
    "    best_model = models_dict['MobileNetV2']\n",
    "    best_model.save('MobileNetV2_garbage_classification.keras')\n",
    "    print(\"\\n最佳模型已保存: MobileNetV2_garbage_classification.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 论文用 LaTeX 表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成 LaTeX 表格\n",
    "if results:\n",
    "    latex_table = \"\"\"\n",
    "\\\\begin{table}[htbp]\n",
    "\\\\centering\n",
    "\\\\caption{Performance Comparison of Different Deep Learning Models}\n",
    "\\\\label{tab:comparison}\n",
    "\\\\begin{tabular}{lccccc}\n",
    "\\\\toprule\n",
    "Model & Accuracy & F1-Score & Size(MB) & Inference(ms) & Params \\\\\\\\\n",
    "\\\\midrule\n",
    "\"\"\"\n",
    "    \n",
    "    for name, res in results.items():\n",
    "        latex_table += f\"{name} & {res['best_val_accuracy']:.4f} & - & \"\n",
    "        latex_table += f\"{res['model_size_mb']:.1f} & {res.get('inference_time_ms', 0):.1f} & \"\n",
    "        latex_table += f\"{res['total_params']/1e6:.1f}M \\\\\\\\\\n\"\n",
    "    \n",
    "    latex_table += \"\"\"\\\\bottomrule\n",
    "\\\\end{tabular}\n",
    "\\\\end{table}\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"LaTeX 表格代码:\")\n",
    "    print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Notebook 运行完成!\")\n",
    "if not results:\n",
    "    print(\"注意: 数据集不可用，训练部分已跳过\")\n",
    "    print(\"请下载数据集到指定目录后重新运行\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
